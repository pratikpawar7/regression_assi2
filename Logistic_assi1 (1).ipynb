{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff629b3-784c-4b29-9c37-59c0e0aec5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Q1. Explain the difference between linear regression and logistic regression models. Provide an example of\n",
    "a scenario where logistic regression would be more appropriate.\n",
    "'''\n",
    "\n",
    "The main difference in the linear and logistic regression is \n",
    "IN Linear regression there is the prediction of contineous value .  it is 1 2 3 4 5 6 7 any contineous value \n",
    "But IN Logistic regression there is the prediction of Yes or NO , it is not a contineous value it is only yes or no .\n",
    "\n",
    "\n",
    "1.Linear Regression:\n",
    "\n",
    "Used for predicting continuous outcomes.\n",
    "    1..Establishes a linear relationship between the dependent and independent variables.\n",
    "    2.Example: Predicting house prices based on features like size, number of rooms, and location.\n",
    "\n",
    "\n",
    "2.Logistic Regression:\n",
    "\n",
    "Used for 1.predicting categorical outcomes, particularly binary outcomes (0 or 1).\n",
    "          2.Models the probability of a particular class or event existing.\n",
    "Example: Predicting whether a patient has a disease (1) or not (0) based on medical test results.\n",
    "\n",
    "\n",
    "Scenario for Logistic Regression:\n",
    "\n",
    "Predicting whether an email is spam (1) or not spam (0) based on features like the\n",
    "presence of certain keywords, email length, and sender's email address."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c59c46-1dc1-41b8-a784-be3c2e4758df",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Q2. What is the cost function used in logistic regression, and how is it optimized?\n",
    "'''\n",
    "Cost function is mean squared error \n",
    "It gives us how accurate output is of our model.\n",
    "\n",
    "It measures the error in the acutal and predicted value \n",
    "The cost funtion is optimised using Gradient decent . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b986dfb-81a1-49b0-b863-15d0a07c7093",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Q3. Explain the concept of regularization in logistic regression and how it helps prevent overfitting.\n",
    "'''\n",
    "Regulrization is adding penalty to the cost function. \n",
    "it is used for reduce overfitting . \n",
    "\n",
    "There are two types of regulrization :\n",
    "    1.l1 regulrization means Lasso regression.\n",
    "    2.l2 regression means Ridge regression. \n",
    "    \n",
    "How Regularization Helps Prevent Overfitting:\n",
    "    1.Penalizes Complexity: Regularization adds a penalty for large coefficients, \n",
    "                            effectively reducing the complexity of the model.\n",
    "    2.Shrinks Coefficients: By shrinking the coefficients, regularization forces the essentioal features of model \n",
    "                            to focus on the most important features, thus preventing it from capturing noise in the data.\n",
    "    3.Improves Generalization: With reduced complexity and focus on essential features, the \n",
    "                               model generalizes better to new data, improving its performance on unseen datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41938feb-957d-48b2-b29d-5ae805c03a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Q4. What is the ROC curve, and how is it used to evaluate the performance of the logistic regression\n",
    "model?\n",
    "'''\n",
    "\n",
    "The Receiver Operating Characteristic (ROC) curve is a graphical representation used to evaluate the \n",
    "performance of a binary classification model, such as logistic regression. \n",
    "\n",
    "It plots the True Positive Rate (TPR) against the False Positive Rate (FPR) at various threshold settings.\n",
    "\n",
    "      True Positives+False Negatives\n",
    "TPR=   ---------------------------        \n",
    "             True Positives\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979cc1a5-679e-48c3-bee8-86591389fcf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Q5. What are some common techniques for feature selection in logistic regression? How do these\n",
    "techniques help improve the model's performance?\n",
    "'''\n",
    " \n",
    "Lasso regression is the one of the good technique to feture seletion in regression . \n",
    "It removes the less important feature from the dataset using lasso regression technique.\n",
    "\n",
    "Here are some common techniques:\n",
    "\n",
    "1.Univariate Statistical Tests:\n",
    "2.Recursive Feature Elimination (RFE):\n",
    "3.Regularization (L1 Regularization - Lasso):\n",
    "4.Tree-based Methods (e.g., Random Forest, Gradient Boosting):\n",
    "5.Principal Component Analysis (PCA):\n",
    "6.Correlation Matrix with Heatmap:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5cfd49-645e-4a37-b999-ae01ee6e5566",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Q6. How can you handle imbalanced datasets in logistic regression? What are some strategies for dealing\n",
    "with class imbalance?\n",
    "'''\n",
    "\n",
    "For handling imbalanced dataset we use followeing techniqes :\n",
    "    \n",
    "    1.SMOTE :Sinthetic minority oversampling technique. \n",
    "    2.Resampling technique : oversampling or undersampling.\n",
    "    3.Therhold adjusting:\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07355d9a-756b-4c37-ae6b-1f69f7ee6b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Q7. Can you discuss some common issues and challenges that may arise when implementing logistic\n",
    "regression, and how they can be addressed? For example, what can be done if there is multicollinearity\n",
    "among the independent variables?\n",
    "'''\n",
    "If there is multicollinearity in the independent variables then it auotmatically drop from the columns . \n",
    "\n",
    "Multicollinearity\n",
    "Issue: When independent variables are highly correlated, it can inflate the variance of \n",
    "        the coefficient estimates and make the model unstable.\n",
    "    \n",
    "solution :\n",
    "    Remove Correlated Features: Use a correlation matrix or variance inflation factor (VIF) to identify and remove highly correlated features.\n",
    "    Regularization: Apply L1 (Lasso) or L2 (Ridge) regularization to reduce the impact of multicollinearity.\n",
    "    Principal Component Analysis (PCA): use PCA technique .\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0841dd-ea17-4828-9a1e-f653e30b5b28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdde86ca-917a-4f6d-b140-eaa3c816fec6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
